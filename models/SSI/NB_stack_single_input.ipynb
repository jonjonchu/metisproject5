{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack single-input model\n",
    "convolve input, send to encoder, decoder, deconvolve decoder output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T16:02:13.471674Z",
     "start_time": "2020-06-15T16:02:13.436638Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T16:02:14.243042Z",
     "start_time": "2020-06-15T16:02:14.237371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.2.0-dlenv\n"
     ]
    }
   ],
   "source": [
    "print(\"tensorflow version:\",tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input dimension variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T16:02:14.878387Z",
     "start_time": "2020-06-15T16:02:14.873906Z"
    }
   },
   "outputs": [],
   "source": [
    "frames = 1\n",
    "channels = 1\n",
    "pixels_x = 21\n",
    "pixels_y = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Old versions of Tensorflow (<2.2) may not have support for initial_state on ConvLSTM2D cells. \n",
    "Please follow the instructions here: https://stackoverflow.com/questions/50253138/convlstm2d-initial-state-assertion-error to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T16:02:16.364824Z",
     "start_time": "2020-06-15T16:02:16.352422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./stack_single_input_1F\n"
     ]
    }
   ],
   "source": [
    "model_dir = \".\"\n",
    "model_folder = \"/\"\n",
    "model_name = 'stack_single_input_'+str(frames)+'F'\n",
    "print(model_dir+model_folder+model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Stack A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Full_stack\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "model_input (InputLayer)        [(None, 1, 21, 21)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 1, 21, 21)    0           model_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "convA1 (Conv2D)                 (None, 8, 9, 9)      208         gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "convA1_bn (BatchNormalization)  (None, 8, 9, 9)      32          convA1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convA2 (Conv2D)                 (None, 16, 7, 7)     1168        convA1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convA2_bn (BatchNormalization)  (None, 16, 7, 7)     64          convA2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convA3 (Conv2D)                 (None, 16, 3, 3)     2320        convA2_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convA3_bn (BatchNormalization)  (None, 16, 3, 3)     64          convA3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(1, None, 16, 3, 3) 0           convA3_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(1, None, 16, 3, 3) 0           convA3_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder1 (ConvLSTM2D)           [(1, None, 16, 3, 3) 51264       tf_op_layer_ExpandDims[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "decoder1 (ConvLSTM2D)           [(1, None, 16, 3, 3) 51264       tf_op_layer_ExpandDims_1[0][0]   \n",
      "                                                                 encoder1[0][1]                   \n",
      "                                                                 encoder1[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 16, 3, 3)]   0           decoder1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "deconv1 (Conv2DTranspose)       (None, 16, 7, 7)     2320        tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "deconv1_bn (BatchNormalization) (None, 16, 7, 7)     64          deconv1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "deconv2 (Conv2DTranspose)       (None, 8, 9, 9)      1160        deconv1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "deconv2_bn (BatchNormalization) (None, 8, 9, 9)      32          deconv2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "deconv3 (Conv2DTranspose)       (None, 1, 21, 21)    201         deconv2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "deconv3_bn (BatchNormalization) (None, 1, 21, 21)    4           deconv3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_2 (Tenso [(1, None, 1, 21, 21 0           deconv3_bn[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 110,165\n",
      "Trainable params: 110,035\n",
      "Non-trainable params: 130\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Conv Stack Vars\n",
    "input_shape = (1,21,21)\n",
    "weight_decay=1e-5\n",
    "filters=[8, 16, 16]\n",
    "kernel_sizes = [(5,5), (3,3), (3,3)]\n",
    "strides=[(2,2),(1,1),(2,2)]\n",
    "bias_init=0.1\n",
    "output_activation=tf.nn.sigmoid,\n",
    "\n",
    "########### INPUT PARSING ###########\n",
    "\n",
    "inputs = layers.Input(name=\"model_input\",\n",
    "                      shape = (channels, pixels_x, pixels_y))\n",
    "# (None, ch, x, y)\n",
    "# inputs = tf.reshape(inputs,shape=[-1, channels, pixels_x, pixels_y])\n",
    "inputA = layers.GaussianNoise(0.1)(inputs)\n",
    "\n",
    "########### CONV A (input t=0) ################\n",
    "\n",
    "name = \"convA\"\n",
    "\n",
    "Conv2D_1 = layers.Conv2D(name=name+\"1\",\n",
    "                         data_format='channels_first',\n",
    "                         filters=filters[0],\n",
    "                         kernel_size=kernel_sizes[0],\n",
    "                         strides=strides[0],\n",
    "                         kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
    "                         activity_regularizer=tf.keras.regularizers.l2(l=weight_decay),\n",
    "                         activation=\"relu\",\n",
    "                         )\n",
    "BN_1 = layers.BatchNormalization(axis=1, name=name+\"1_bn\")\n",
    "Conv2D_2 = layers.Conv2D(name=name+\"2\",\n",
    "                         data_format='channels_first',\n",
    "                         filters=filters[1],\n",
    "                         kernel_size=kernel_sizes[1],\n",
    "                         strides=strides[1],\n",
    "                         kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
    "                         activity_regularizer=tf.keras.regularizers.l2(l=weight_decay),\n",
    "                         activation=\"relu\",\n",
    "                         )\n",
    "BN_2 = layers.BatchNormalization(axis=1, name=name+\"2_bn\")\n",
    "Conv2D_3 = layers.Conv2D(name=name+\"3\",\n",
    "                         data_format='channels_first',\n",
    "                         filters=filters[2],\n",
    "                         kernel_size=kernel_sizes[2],\n",
    "                         strides=strides[2],\n",
    "                         kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
    "                         activity_regularizer=tf.keras.regularizers.l2(l=weight_decay),\n",
    "                         activation=\"relu\",\n",
    "                         )\n",
    "BN_3 = layers.BatchNormalization(axis=1, name=name+\"3_bn\")\n",
    "\n",
    "\n",
    "stack = Conv2D_1(inputA)\n",
    "stack = BN_1(stack)\n",
    "stack = Conv2D_2(stack)\n",
    "stack = BN_2(stack)\n",
    "stack = Conv2D_3(stack)\n",
    "convA_output = BN_3(stack)\n",
    "\n",
    "####################################\n",
    "####### ENCODER-DEC0DER ############\n",
    "\n",
    "############# ENCODER ##############\n",
    "\n",
    "# first time-step\n",
    "i = 0\n",
    "# get input_images and output_images as one tensor\n",
    "encoder_input = tf.expand_dims(convA_output, 0)\n",
    "encoder_cell_1 = layers.ConvLSTM2D(name=\"encoder{}\".format(i+1),\n",
    "                                   filters = filters[-1],\n",
    "                                   kernel_size=(5,5),\n",
    "                                   padding='same',\n",
    "                                   data_format='channels_first',\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "_, state_h, state_c = encoder_cell_1(encoder_input)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "##### DECODER #####\n",
    "\n",
    "decoder_input = tf.expand_dims(convA_output, 0)\n",
    "decoder_cell_1 = layers.ConvLSTM2D(name=\"decoder{}\".format(i+1),\n",
    "                                   filters = filters[-1],\n",
    "                                   kernel_size=(5,5),\n",
    "                                   padding='same',\n",
    "                                   data_format='channels_first',\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "decoder_output, _, _ = decoder_cell_1(decoder_input, initial_state = encoder_states)\n",
    "reshaped_decoder_output = tf.reshape(decoder_output,shape=[-1, filters[-1], 3, 3])\n",
    "#################################\n",
    "######## DECONV STACK ###########\n",
    "\n",
    "name = \"deconv\"\n",
    "rev_filters = filters[::-1]\n",
    "rev_filters = rev_filters[1:] + [channels]\n",
    "rev_kernel_sizes = kernel_sizes[::-1]\n",
    "rev_strides = strides[::-1]\n",
    "\n",
    "deConv2D_1 = layers.Conv2DTranspose(name=name+\"1\",\n",
    "                         data_format='channels_first',\n",
    "                         filters=rev_filters[0],\n",
    "                         kernel_size=rev_kernel_sizes[0],\n",
    "                         strides=rev_strides[0],\n",
    "                         kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
    "                         activity_regularizer=tf.keras.regularizers.l2(l=weight_decay),\n",
    "                         activation=\"relu\",\n",
    "                         )\n",
    "deBN_1 = layers.BatchNormalization(axis=1, name=name+\"1_bn\")\n",
    "deConv2D_2 = layers.Conv2DTranspose(name=name+\"2\",\n",
    "                         data_format='channels_first',\n",
    "                         filters=rev_filters[1],\n",
    "                         kernel_size=rev_kernel_sizes[1],\n",
    "                         strides=rev_strides[1],\n",
    "                         kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
    "                         activity_regularizer=tf.keras.regularizers.l2(l=weight_decay),\n",
    "                         activation=\"relu\",\n",
    "                         )\n",
    "deBN_2 = layers.BatchNormalization(axis=1, name=name+\"2_bn\")\n",
    "deConv2D_3 = layers.Conv2DTranspose(name=name+\"3\",\n",
    "                         data_format='channels_first',\n",
    "                         filters=rev_filters[2],\n",
    "                         kernel_size=rev_kernel_sizes[2],\n",
    "                         strides=rev_strides[2],\n",
    "                         kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
    "                         activity_regularizer=tf.keras.regularizers.l2(l=weight_decay),\n",
    "                         activation=\"relu\",\n",
    "                         )\n",
    "deBN_3 = layers.BatchNormalization(axis=1, name=name+\"3_bn\")\n",
    "\n",
    "# reshaped = reshaper(decoder_output)\n",
    "stack = deConv2D_1(reshaped_decoder_output)\n",
    "stack = deBN_1(stack)\n",
    "stack = deConv2D_2(stack)\n",
    "stack = deBN_2(stack)\n",
    "stack = deConv2D_3(stack)\n",
    "stack = deBN_3(stack)\n",
    "deconv_output = tf.expand_dims(stack, 0)\n",
    "\n",
    "#######################\n",
    "\n",
    "full_model = tf.keras.Model(name=\"Full_stack\",\n",
    "                       inputs = inputs,\n",
    "                       outputs = deconv_output)\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T16:05:00.478498Z",
     "start_time": "2020-06-15T16:05:00.429464Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(\n",
    "    model = full_model,\n",
    "    filepath = model_dir+model_folder+model_name+'.h5',\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format='tf',\n",
    "    signatures=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
