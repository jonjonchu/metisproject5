{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.2.0-dlenv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "print(\"tensorflow version:\",tf.__version__)\n",
    "\n",
    "import wandb\n",
    "from wandb.tensorflow import WandbHook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wandb config and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/jonjonchu/whether-predictor\" target=\"_blank\">https://app.wandb.ai/jonjonchu/whether-predictor</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/jonjonchu/whether-predictor/runs/fmrqweud\" target=\"_blank\">https://app.wandb.ai/jonjonchu/whether-predictor/runs/fmrqweud</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/jonjonchu/whether-predictor/runs/fmrqweud"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(name='sparky',\n",
    "           group='0',\n",
    "           project='whether-predictor',\n",
    "           sync_tensorboard=True,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"epochs\": 4,\n",
    "          \"frames\": 1,\n",
    "          \"channels\": 1,\n",
    "          \"pixels_x\": 21,\n",
    "          \"pixels_y\": 21,\n",
    "          \"input_shape\": (1, 21, 21),\n",
    "          \"filters\": [8, 16, 16],\n",
    "          \"kernel_sizes\": [(5,5), (3,3), (3,3)],\n",
    "          \"strides\": [(1,1), (1,1), (1,1),],\n",
    "          \"bias_init\": 0.1,\n",
    "          \"weight_decay\": 1e-5,\n",
    "         }\n",
    "wandb.config.update(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(name=\"model_input\",\n",
    "                      shape = wandb.config.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_noised = layers.GaussianNoise(0.1, name=\"input_noised\")(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"conv_\"\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_layers):\n",
    "    # Create layers\n",
    "    conv_cell = layers.Conv2D(name=\"conv_{}\".format(i+1),\n",
    "                             data_format='channels_first',\n",
    "                             filters=wandb.config.filters[i],\n",
    "                             kernel_size=wandb.config.kernel_sizes[i],\n",
    "                             strides=wandb.config.strides[i],\n",
    "                             kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
    "                             activity_regularizer=tf.keras.regularizers.l2(l=wandb.config.weight_decay),\n",
    "                             activation=\"relu\",\n",
    "                             )\n",
    "    bn_cell = layers.BatchNormalization(axis=1, name=\"conv_bn_{}\".format(i+1))\n",
    "    \n",
    "    # Link layers together into stack\n",
    "    # Connect previous layer (either input_noised or stack) to conv_cell\n",
    "    if i == 0:\n",
    "        stack =  conv_cell(input_noised)\n",
    "    else:\n",
    "        stack = conv_cell(stack)\n",
    "    # Connect conv_cell to bn unless at end of loop\n",
    "    if i != num_layers-1:\n",
    "        stack = bn_cell(stack)\n",
    "    elif i == num_layers-1:\n",
    "        conv_output = bn_cell(stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = tf.expand_dims(conv_output, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cell = layers.ConvLSTM2D(name=\"encoder{}\".format(i+1),\n",
    "                                 filters = wandb.config.filters[-1],\n",
    "                                 kernel_size=wandb.config.kernel_sizes[0],\n",
    "                                 padding='same',\n",
    "                                 data_format='channels_first',\n",
    "                                 return_sequences=True,\n",
    "                                 return_state=True)\n",
    "_, state_h, state_c = encoder_cell(encoder_input)\n",
    "\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save convolutional stack output shape in configs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 16, 13, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(conv_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config.update({\"conv_output_shape\": tuple(conv_output.shape)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = tf.expand_dims(conv_output, 0, name=\"decoder_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cell = layers.ConvLSTM2D(name=\"decoder{}\".format(i+1),\n",
    "                                   filters=wandb.config.filters[-1],\n",
    "                                   kernel_size=wandb.config.kernel_sizes[0],\n",
    "                                   padding='same',\n",
    "                                   data_format='channels_first',\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "\n",
    "decoder_output, _, _ = decoder_cell(decoder_input, initial_state = encoder_states)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_decoder_output = tf.reshape(decoder_output,\n",
    "                                     shape=[-1,\n",
    "                                            wandb.config.filters[-1],\n",
    "                                            decoder_output.shape[-2],\n",
    "                                            decoder_output.shape[-1]],\n",
    "                                     name=\"decoder_reshaped\",\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deconvolutional Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 8, 1]\n",
      "[8, 16, 16]\n",
      "[[3, 3], [3, 3], [5, 5]]\n",
      "[[5, 5], [3, 3], [3, 3]]\n",
      "[[1, 1], [1, 1], [1, 1]]\n",
      "[[1, 1], [1, 1], [1, 1]]\n"
     ]
    }
   ],
   "source": [
    "rev_filters = wandb.config.filters[::-1]\n",
    "rev_filters = rev_filters[1:] + [wandb.config.channels]\n",
    "rev_kernel_sizes = wandb.config.kernel_sizes[::-1]\n",
    "rev_strides = wandb.config.strides[::-1]\n",
    "print(rev_filters)\n",
    "print(wandb.config.filters)\n",
    "print(rev_kernel_sizes)\n",
    "print(wandb.config.kernel_sizes)\n",
    "print(rev_strides)\n",
    "print(wandb.config.strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_layers):\n",
    "    # Create layers\n",
    "    deconv_cell = layers.Conv2DTranspose(name=\"deconv_{}\".format(i+1),\n",
    "                             data_format='channels_first',\n",
    "                             filters=rev_filters[i],\n",
    "                             kernel_size=rev_kernel_sizes[i],\n",
    "                             strides=rev_strides[i],\n",
    "                             kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
    "                             activity_regularizer=tf.keras.regularizers.l2(l=wandb.config.weight_decay),\n",
    "                             activation=\"relu\",\n",
    "                             )\n",
    "    bn_cell = layers.BatchNormalization(axis=1, name=\"deconv_bn_{}\".format(i+1))\n",
    "    \n",
    "    # Link layers together into stack\n",
    "    # Connect previous layer (either input_noised or stack) to conv_cell\n",
    "    if i == 0:\n",
    "        stack =  deconv_cell(reshaped_decoder_output)\n",
    "    else:\n",
    "        stack = deconv_cell(stack)\n",
    "    # Connect conv_cell to bn unless at end of loop\n",
    "    if i != num_layers-1:\n",
    "        stack = bn_cell(stack)\n",
    "    else:\n",
    "        deconv_output = bn_cell(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.expand_dims(deconv_output, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Full_stack\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "model_input (InputLayer)        [(None, 1, 21, 21)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_noised (GaussianNoise)    (None, 1, 21, 21)    0           model_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 8, 17, 17)    208         input_noised[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_bn_1 (BatchNormalization)  (None, 8, 17, 17)    32          conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 16, 15, 15)   1168        conv_bn_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_bn_2 (BatchNormalization)  (None, 16, 15, 15)   64          conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 16, 13, 13)   2320        conv_bn_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_bn_3 (BatchNormalization)  (None, 16, 13, 13)   64          conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(1, None, 16, 13, 1 0           conv_bn_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_decoder_input (Tens [(1, None, 16, 13, 1 0           conv_bn_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder3 (ConvLSTM2D)           [(1, None, 16, 13, 1 51264       tf_op_layer_ExpandDims[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "decoder3 (ConvLSTM2D)           [(1, None, 16, 13, 1 51264       tf_op_layer_decoder_input[0][0]  \n",
      "                                                                 encoder3[0][1]                   \n",
      "                                                                 encoder3[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_decoder_reshaped (T [(None, 16, 13, 13)] 0           decoder3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "deconv_1 (Conv2DTranspose)      (None, 16, 15, 15)   2320        tf_op_layer_decoder_reshaped[0][0\n",
      "__________________________________________________________________________________________________\n",
      "deconv_bn_1 (BatchNormalization (None, 16, 15, 15)   64          deconv_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "deconv_2 (Conv2DTranspose)      (None, 8, 17, 17)    1160        deconv_bn_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "deconv_bn_2 (BatchNormalization (None, 8, 17, 17)    32          deconv_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "deconv_3 (Conv2DTranspose)      (None, 1, 21, 21)    201         deconv_bn_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "deconv_bn_3 (BatchNormalization (None, 1, 21, 21)    4           deconv_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_5 (Tenso [(1, None, 1, 21, 21 0           deconv_bn_3[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 110,165\n",
      "Trainable params: 110,035\n",
      "Non-trainable params: 130\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_model = tf.keras.Model(name=\"Full_stack\",\n",
    "                       inputs = input_,\n",
    "                       outputs = output)\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
