{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Class example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "  \"\"\"Maps MNIST digits to a triplet (z_mean, z_log_var, z).\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               latent_dim=32,\n",
    "               intermediate_dim=64,\n",
    "               name='encoder',\n",
    "               **kwargs):\n",
    "    super(Encoder, self).__init__(name=name, **kwargs)\n",
    "    self.dense_proj = layers.Dense(intermediate_dim, activation='relu')\n",
    "    self.dense_mean = layers.Dense(latent_dim)\n",
    "    self.dense_log_var = layers.Dense(latent_dim)\n",
    "    self.sampling = Sampling()\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.dense_proj(inputs)\n",
    "    z_mean = self.dense_mean(x)\n",
    "    z_log_var = self.dense_log_var(x)\n",
    "    z = self.sampling((z_mean, z_log_var))\n",
    "    return z_mean, z_log_var, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvStack Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvStack(layers.Layer):\n",
    "  \"\"\"Creates a Conv2D + BatchNorm stack.\n",
    "  If input is (1,21,21), output is (1, 1, 64, 3, 3)\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               input_shape:tuple = (1,21,21),\n",
    "               weight_decay=1e-5,\n",
    "               filters=[32, 64, 64],\n",
    "               kernel_sizes = [(5,5), (3,3), (3,3)],\n",
    "               strides=[(2,2),(1,1),(2,2)],\n",
    "               bias_init=0.1,\n",
    "               output_activation=tf.nn.sigmoid,\n",
    "               name='encoder',\n",
    "               **kwargs):\n",
    "    super(ConvStack, self).__init__(name=name, **kwargs)\n",
    "\n",
    "    self.Conv2D_1 = layers.Conv2D(name=\"conv1\",\n",
    "                                  input_shape = input_shape,\n",
    "                                 data_format='channels_first',\n",
    "                                 filters=filters[0],\n",
    "                                 kernel_size=kernel_sizes[0],\n",
    "                                 strides=strides[0],\n",
    "                                 kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
    "                                 activity_regularizer=tf.keras.regularizers.l2(l=weight_decay),\n",
    "                                 activation=tf.nn.relu,\n",
    "                                 )\n",
    "    self.BN_1 = layers.BatchNormalization(axis=1, name=\"conv1_bn\")\n",
    "    self.Conv2D_2 = layers.Conv2D(name=\"conv2\",\n",
    "                                 data_format='channels_first',\n",
    "                                 filters=filters[1],\n",
    "                                 kernel_size=kernel_sizes[1],\n",
    "                                 strides=strides[1],\n",
    "                                 kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
    "                                 activity_regularizer=tf.keras.regularizers.l2(l=weight_decay),\n",
    "                                 activation=tf.nn.relu,\n",
    "                                 )\n",
    "    self.BN_2 = layers.BatchNormalization(axis=1, name=\"conv2_bn\")\n",
    "    self.Conv2D_3 = layers.Conv2D(name=\"conv3\",\n",
    "                                 data_format='channels_first',\n",
    "                                 filters=filters[2],\n",
    "                                 kernel_size=kernel_sizes[2],\n",
    "                                 strides=strides[2],\n",
    "                                 kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
    "                                 activity_regularizer=tf.keras.regularizers.l2(l=weight_decay),\n",
    "                                 activation=tf.nn.relu,\n",
    "                                 )\n",
    "    self.BN_3 = layers.BatchNormalization(axis=1, name=\"conv3_bn\")\n",
    "    \n",
    "\n",
    "  def call(self, inputs):\n",
    "    \"\"\"Construct the stack and pass the inputs thru\"\"\"\n",
    "    stack = self.Conv2D_1(inputs)\n",
    "    stack = self.BN_1(stack)\n",
    "    stack = self.Conv2D_2(stack)\n",
    "    stack = self.BN_2(stack)\n",
    "    stack = self.Conv2D_3(stack)\n",
    "    stack = self.BN_3(stack)\n",
    "    # Add an empty dim to pass to Encoder\n",
    "    return tf.expand_dims(stack, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 64, 3, 3), dtype=float32, numpy=\n",
       "array([[[[[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [1.54450592e-02, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[1.18545834e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "          [2.62208506e-02, 2.73919627e-02, 0.00000000e+00],\n",
       "          [0.00000000e+00, 6.35615364e-02, 0.00000000e+00]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[1.18993811e-01, 3.44521329e-02, 0.00000000e+00],\n",
       "          [6.33240268e-02, 6.98077232e-02, 8.45875684e-03],\n",
       "          [8.84230435e-02, 4.33336906e-02, 3.68882082e-02]],\n",
       "\n",
       "         [[8.09396431e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 1.09764755e-01],\n",
       "          [0.00000000e+00, 0.00000000e+00, 3.99504751e-02]],\n",
       "\n",
       "         [[0.00000000e+00, 2.78324895e-02, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[3.29028405e-02, 4.67102565e-02, 0.00000000e+00],\n",
       "          [2.18724133e-03, 0.00000000e+00, 1.81761868e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 5.78244263e-03, 3.39279436e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 2.75223306e-03]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 8.74620955e-03],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[7.92757347e-02, 5.14670722e-02, 7.66382739e-02],\n",
       "          [9.88438725e-02, 0.00000000e+00, 5.34185693e-02],\n",
       "          [3.62034030e-02, 5.36288284e-02, 0.00000000e+00]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 4.61544879e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[1.49925146e-02, 2.46696565e-02, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [2.16028746e-02, 1.27136782e-02, 3.65908109e-02]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [1.37092816e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "          [6.00924529e-02, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[1.18066505e-01, 1.01142395e-02, 1.15345977e-01],\n",
       "          [5.27866706e-02, 1.56916183e-04, 0.00000000e+00],\n",
       "          [5.06206416e-02, 2.07271837e-02, 5.98331615e-02]],\n",
       "\n",
       "         [[0.00000000e+00, 3.65059241e-03, 1.18568121e-02],\n",
       "          [4.47119074e-03, 8.18001223e-04, 5.31203933e-02],\n",
       "          [0.00000000e+00, 7.39315804e-03, 0.00000000e+00]],\n",
       "\n",
       "         [[3.60638946e-02, 6.13368861e-03, 7.12369243e-03],\n",
       "          [5.16161043e-03, 7.90675506e-02, 5.91929480e-02],\n",
       "          [0.00000000e+00, 6.60513043e-02, 0.00000000e+00]],\n",
       "\n",
       "         [[0.00000000e+00, 4.45015132e-02, 6.10751286e-03],\n",
       "          [5.42881750e-02, 1.74436551e-02, 0.00000000e+00],\n",
       "          [5.13909720e-02, 3.26443762e-02, 2.98019275e-02]],\n",
       "\n",
       "         [[9.25750434e-02, 1.02068782e-01, 7.16421530e-02],\n",
       "          [1.59377083e-01, 1.15271680e-01, 1.49123669e-01],\n",
       "          [1.51777074e-01, 3.67880538e-02, 1.19277164e-01]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 2.62291208e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [2.40293257e-02, 2.15485902e-03, 2.33398713e-02]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[3.79731879e-02, 1.21259978e-02, 5.46496063e-02],\n",
       "          [0.00000000e+00, 5.83539866e-02, 0.00000000e+00],\n",
       "          [4.36825752e-02, 7.04533905e-02, 5.02728038e-02]],\n",
       "\n",
       "         [[2.29892023e-02, 7.04923794e-02, 5.92177548e-02],\n",
       "          [6.53614700e-02, 1.01364478e-01, 7.17731519e-03],\n",
       "          [5.82162812e-02, 2.42773835e-02, 3.35617922e-02]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 5.01842424e-03, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[5.56056537e-02, 0.00000000e+00, 2.29427852e-02],\n",
       "          [2.42338311e-02, 5.59357218e-02, 0.00000000e+00],\n",
       "          [1.83582269e-02, 0.00000000e+00, 1.14342012e-01]],\n",
       "\n",
       "         [[1.37250200e-01, 1.07167311e-01, 6.85909763e-02],\n",
       "          [1.30157456e-01, 5.42480461e-02, 7.21753612e-02],\n",
       "          [7.94842392e-02, 6.36695549e-02, 0.00000000e+00]],\n",
       "\n",
       "         [[1.10977463e-01, 8.30057412e-02, 1.10208588e-02],\n",
       "          [0.00000000e+00, 4.21214141e-02, 6.62963539e-02],\n",
       "          [0.00000000e+00, 1.77369360e-02, 0.00000000e+00]],\n",
       "\n",
       "         [[1.40048891e-01, 0.00000000e+00, 5.27105220e-02],\n",
       "          [3.94355543e-02, 9.84930340e-03, 2.99632996e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 2.64146775e-02],\n",
       "          [0.00000000e+00, 5.09188883e-03, 8.02529696e-03],\n",
       "          [0.00000000e+00, 4.15987819e-02, 0.00000000e+00]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[1.09365890e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 6.22496009e-02],\n",
       "          [2.83901598e-02, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[0.00000000e+00, 2.37354692e-02, 4.75139432e-02],\n",
       "          [9.83796790e-02, 7.37470239e-02, 0.00000000e+00],\n",
       "          [3.23869139e-02, 9.25061926e-02, 3.81667279e-02]],\n",
       "\n",
       "         [[3.79866473e-02, 2.04924215e-02, 5.03015928e-02],\n",
       "          [1.43453449e-01, 5.76523207e-02, 1.73619762e-02],\n",
       "          [9.38153753e-05, 8.14644899e-03, 0.00000000e+00]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 2.80845426e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[8.53297040e-02, 1.00017644e-01, 8.37210640e-02],\n",
       "          [3.61549028e-04, 5.87213300e-02, 0.00000000e+00],\n",
       "          [5.57056405e-02, 9.76055162e-04, 4.49756123e-02]],\n",
       "\n",
       "         [[0.00000000e+00, 1.61652323e-02, 4.91110720e-02],\n",
       "          [6.47160318e-03, 0.00000000e+00, 1.32640889e-02],\n",
       "          [0.00000000e+00, 9.13417619e-03, 0.00000000e+00]],\n",
       "\n",
       "         [[5.31932004e-02, 6.58322871e-02, 0.00000000e+00],\n",
       "          [7.83323571e-02, 1.32224709e-01, 5.76962642e-02],\n",
       "          [6.33552596e-02, 9.51884091e-02, 1.62344724e-01]],\n",
       "\n",
       "         [[3.49763744e-02, 5.22660427e-02, 4.54872698e-02],\n",
       "          [4.40425165e-02, 6.91493377e-02, 0.00000000e+00],\n",
       "          [8.74028265e-05, 2.52838992e-02, 9.11971033e-02]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 6.05688021e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [9.54903103e-03, 8.56311899e-03, 9.38417856e-03]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [9.91975144e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 3.93262170e-02, 1.42226499e-02]],\n",
       "\n",
       "         [[9.18463171e-02, 5.74306771e-02, 2.35756859e-02],\n",
       "          [3.84424217e-02, 2.25117430e-02, 5.88876009e-02],\n",
       "          [1.13997916e-02, 6.41972497e-02, 1.55254649e-02]],\n",
       "\n",
       "         [[1.87447276e-02, 2.93410737e-02, 3.84950377e-02],\n",
       "          [3.82291339e-02, 5.59036843e-02, 6.38901209e-03],\n",
       "          [2.71353219e-02, 1.04022101e-02, 0.00000000e+00]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [3.37389298e-02, 0.00000000e+00, 4.18080464e-02]],\n",
       "\n",
       "         [[2.83166021e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 4.32747938e-02, 1.55360773e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 2.66089700e-02]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [2.42916867e-02, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 5.19580804e-02],\n",
       "          [8.95328224e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 4.06906754e-02, 1.09943002e-01]],\n",
       "\n",
       "         [[4.39284295e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 6.97837695e-02, 0.00000000e+00],\n",
       "          [7.15198740e-02, 1.56980101e-02, 0.00000000e+00]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 8.33188370e-03],\n",
       "          [0.00000000e+00, 3.00272629e-02, 0.00000000e+00],\n",
       "          [0.00000000e+00, 4.64187413e-02, 1.04640007e-01]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[6.83549196e-02, 6.82163760e-02, 1.42517053e-02],\n",
       "          [0.00000000e+00, 8.52181464e-02, 1.75830927e-02],\n",
       "          [0.00000000e+00, 3.46269906e-02, 7.35490024e-02]],\n",
       "\n",
       "         [[5.50588593e-03, 5.31378314e-02, 9.60131437e-02],\n",
       "          [3.33119966e-02, 1.49746565e-02, 0.00000000e+00],\n",
       "          [9.66511760e-03, 8.18629190e-02, 1.24015380e-02]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [7.45344767e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 3.73916663e-02, 5.60563914e-02]],\n",
       "\n",
       "         [[3.87536399e-02, 2.67688418e-03, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 9.30186734e-02]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 7.74512161e-03]],\n",
       "\n",
       "         [[7.89319053e-02, 5.57410009e-02, 3.91775817e-02],\n",
       "          [5.72929867e-02, 6.66399226e-02, 1.32250264e-01],\n",
       "          [2.96577178e-02, 2.03583799e-02, 4.35956381e-02]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[1.53532565e-01, 1.13386348e-01, 9.73822773e-02],\n",
       "          [1.36798039e-01, 9.02888179e-02, 1.42208666e-01],\n",
       "          [7.84619749e-02, 5.45947291e-02, 1.13614134e-01]],\n",
       "\n",
       "         [[0.00000000e+00, 2.19330657e-03, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [3.09093948e-02, 3.88853159e-03, 0.00000000e+00]],\n",
       "\n",
       "         [[4.99307774e-02, 9.99639258e-02, 1.61883123e-02],\n",
       "          [0.00000000e+00, 9.10006538e-02, 4.44020107e-02],\n",
       "          [7.90736973e-02, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[0.00000000e+00, 2.23845337e-02, 9.94750783e-02],\n",
       "          [4.10019085e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "         [[2.75334669e-03, 6.22864030e-02, 2.54621338e-02],\n",
       "          [0.00000000e+00, 4.25864682e-02, 4.90626087e-04],\n",
       "          [0.00000000e+00, 4.76932079e-02, 5.49215451e-02]]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.Variable(tf.random.uniform([1,1,21,21], -1, 1))\n",
    "convstack = ConvStack()\n",
    "convstack.call(inputs)\n",
    "# stack.call(input for inputs in tf.unstack(inputs,num=24, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, name='Encoder_Stack', cells=24, cell_input_shape=(1, 1, 64, 3, 3), lstm_layers=1, \n",
    "                 lstm_ksize_input=(3, 3), lstm_ksize_hidden=(5, 5),\n",
    "                 lstm_use_peepholes=True, lstm_cell_clip=None, \n",
    "                 lstm_bn_input_hidden=False, \n",
    "                 lstm_bn_hidden_hidden=False,\n",
    "                 lstm_bn_peepholes=False,):\n",
    "        \n",
    "        super(Encoder, self).__init__(name=name)\n",
    "        # create a list of InputLayers\n",
    "        self.input_layers = []\n",
    "        # create a list of ConvLSTM cells\n",
    "        self.encoder_cells = []\n",
    "        self.encoder_states = ['barf']\n",
    "        \n",
    "        \n",
    "        i = 0\n",
    "        # First Frame\n",
    "        self.encoder_cells.append(layers.ConvLSTM2D(input_shape = cell_input_shape,\n",
    "                                   name=\"encoderConvLSTM{}\".format(i+1),\n",
    "                               filters = lstm_layers,\n",
    "                               kernel_size=lstm_ksize_input,\n",
    "                               padding='same',\n",
    "                               data_format='channels_first',\n",
    "                               return_sequences=True,\n",
    "                               return_state=True)\n",
    "        )\n",
    "        \n",
    "        # for each frame, create an InputLayer and corresponding ConvLSTM cell\n",
    "        for i in range(1, cells):\n",
    "            self.input_layers.append(\n",
    "                layers.Input(name=\"encoder{}_input\".format(i+1),\n",
    "                          shape=cell_input_shape)\n",
    "            )\n",
    "            \n",
    "            self.encoder_cells.append(layers.ConvLSTM2D(name=\"encoderConvLSTM{}\".format(i+1),\n",
    "                                   filters = lstm_layers,\n",
    "                                   kernel_size=lstm_ksize_hidden,\n",
    "                                   padding='same',\n",
    "                                   data_format='channels_first',\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "            )\n",
    "        \n",
    "    # input to call() will be a list of tensors of shape=(1, 1, 64, 3, 3)\n",
    "    # call() will take list of inputs and assign each to InputLayer\n",
    "    # call returns\n",
    "    def call(self, inputs_list):\n",
    "#             assert len(inputs_list) == len(self.input_layers), \"Input list length does not match # input layers in stack\"\n",
    "        assert len(inputs_list) == len(self.encoder_cells), \"Input list length does not match # encoder cells in stack\"\n",
    "\n",
    "        # connect each input to its corresponding InputLayer,\n",
    "        # and connect encoder hidden & cell states \n",
    "\n",
    "#             current_input = self.input_layers[0](inputs_list[0])\n",
    "        _, self.state_h, self.state_c = self.encoder_cells[0](inputs_list[0])\n",
    "        print(i, self.state_h.shape, self.state_c.shape)\n",
    "        self.encoder_states = [self.state_h, self.state_c]\n",
    "\n",
    "        for i in range(1, len(inputs_list)):\n",
    "#                 current_input = self.input_layers[i](inputs_list[i])\n",
    "            _, self.state_h, self.state_c = self.encoder_cells[i](inputs_list[i], initial_state = self.encoder_states)\n",
    "            print(i, self.state_h.shape, self.state_c.shape)\n",
    "            self.encoder_states = [self.state_h, self.state_c]\n",
    "        return self.encoder_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test Encoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'encoderConvLSTM1',\n",
       " 'trainable': True,\n",
       " 'dtype': 'float32',\n",
       " 'return_sequences': True,\n",
       " 'return_state': True,\n",
       " 'go_backwards': False,\n",
       " 'stateful': False,\n",
       " 'unroll': False,\n",
       " 'time_major': False,\n",
       " 'filters': 1,\n",
       " 'kernel_size': (3, 3),\n",
       " 'strides': (1, 1),\n",
       " 'padding': 'same',\n",
       " 'data_format': 'channels_first',\n",
       " 'dilation_rate': (1, 1),\n",
       " 'activation': 'tanh',\n",
       " 'recurrent_activation': 'hard_sigmoid',\n",
       " 'use_bias': True,\n",
       " 'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "  'config': {'seed': None}},\n",
       " 'recurrent_initializer': {'class_name': 'Orthogonal',\n",
       "  'config': {'gain': 1.0, 'seed': None}},\n",
       " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       " 'unit_forget_bias': True,\n",
       " 'kernel_regularizer': None,\n",
       " 'recurrent_regularizer': None,\n",
       " 'bias_regularizer': None,\n",
       " 'activity_regularizer': None,\n",
       " 'kernel_constraint': None,\n",
       " 'recurrent_constraint': None,\n",
       " 'bias_constraint': None,\n",
       " 'dropout': 0.0,\n",
       " 'recurrent_dropout': 0.0}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enco.encoder_cells[0].get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You cannot build your model by calling `build` if your layers do not support float type inputs. Instead, in order to instantiate and build your model, `call` your model on real tensor data (of the correct dtype).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-2c872125904e>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs_list)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m#             assert len(inputs_list) == len(self.input_layers), \"Input list length does not match # input layers in stack\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_cells\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Input list length does not match # encoder cells in stack\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0;34m\"Please call `x.shape` rather than `len(x)` for \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m                     \"shape information.\".format(self.name))\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: len is not well defined for symbolic Tensors. (Placeholder:0) Please call `x.shape` rather than `len(x)` for shape information.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-3c4b447a33f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adadelta'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   metrics=['accuracy', 'mean_absolute_error'])\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0menco_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0menco_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# x = enco.call(inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m           raise ValueError('You cannot build your model by calling `build` '\n\u001b[0m\u001b[1;32m    688\u001b[0m                            \u001b[0;34m'if your layers do not support float type inputs. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                            \u001b[0;34m'Instead, in order to instantiate and build your '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You cannot build your model by calling `build` if your layers do not support float type inputs. Instead, in order to instantiate and build your model, `call` your model on real tensor data (of the correct dtype)."
     ]
    }
   ],
   "source": [
    "enco_model = Encoder(cells=1)\n",
    "inputs = [tf.Variable(tf.random.uniform([1, 1, 64, 3, 3], -1, 1))]\n",
    "enco_model.compile(loss='mean_squared_error',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy', 'mean_absolute_error'])\n",
    "enco_model.build((1,1,64,3,3))\n",
    "enco_model.summary()\n",
    "# x = enco.call(inputs)\n",
    "# len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, cells=24, cell_input_shape=(1, 1, 64, 3, 3), lstm_layers=1, \n",
    "                 lstm_ksize_input=(3, 3), lstm_ksize_hidden=(5, 5),\n",
    "                 lstm_use_peepholes=True, lstm_cell_clip=None, \n",
    "                 lstm_bn_input_hidden=False, \n",
    "                 lstm_bn_hidden_hidden=False,\n",
    "                 lstm_bn_peepholes=False,):\n",
    "        # create a list of InputLayers\n",
    "        self.input_layers = []\n",
    "        # create a list of ConvLSTM cells\n",
    "        self.decoder_cells = []\n",
    "        # Decoder sends output\n",
    "        self.decoder_outputs = []\n",
    "        \n",
    "        # First Frame\n",
    "        self.input_layers.append(\n",
    "            layers.Input(name=\"decoder{}_input\".format(0),\n",
    "                      shape=cell_input_shape)\n",
    "        )\n",
    "\n",
    "        self.decoder_cells.append(layers.ConvLSTM2D(name=\"decoder{}\".format(0),\n",
    "                               filters = lstm_layers,\n",
    "                               kernel_size=lstm_ksize_input,\n",
    "                               padding='same',\n",
    "                               data_format='channels_first',\n",
    "                               return_sequences=True,\n",
    "                               return_state=True)\n",
    "        )\n",
    "        \n",
    "        # for each frame, create an InputLayer and corresponding ConvLSTM cell\n",
    "        for i in range(1, cells):\n",
    "            self.input_layers.append(\n",
    "                layers.Input(name=\"decoder{}_input\".format(i+1),\n",
    "                          shape=cell_input_shape)\n",
    "            )\n",
    "            \n",
    "            self.decoder_cells.append(layers.ConvLSTM2D(name=\"decoder{}\".format(i+1),\n",
    "                                   filters = lstm_layers,\n",
    "                                   kernel_size=lstm_ksize_hidden,\n",
    "                                   padding='same',\n",
    "                                   data_format='channels_first',\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "            )\n",
    "        \n",
    "    # input to call() will be a list of tensors of shape=(1, 1, 64, 3, 3)\n",
    "    # call() will take list of inputs and assign each to InputLayer\n",
    "    def call(self, inputs_list, encoder_states):\n",
    "        assert len(inputs_list) == len(self.input_layers), \"Input list length does not match # input layers in stack\"\n",
    "        assert len(inputs_list) == len(self.decoder_cells), \"Input list length does not match # encoder cells in stack\"\n",
    "\n",
    "        # initialize first decoder cell with encoder states\n",
    "        current_input = self.input_layers[0](inputs_list[0])\n",
    "        decoder_output, state_h, state_c = self.decoder_cells[0](current_input, initial_state = encoder_states)\n",
    "        decoder_states = [state_h, state_c]\n",
    "        self.decoder_outputs.append(decoder_output)\n",
    "\n",
    "        for i in range(1, len(inputs_list)):\n",
    "            current_input = self.input_layers[i](inputs_list[i])\n",
    "            _, state_h, state_c = self.decoder_cells[i](current_input, initial_state = decoder_states)\n",
    "            decoder_states = [state_h, state_c]\n",
    "        return self.decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "call() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-e74e26ec8505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdeco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdeco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0menco_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: call() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "deco = Decoder()\n",
    "inputs = [tf.Variable(tf.random.uniform([1, 1, 64, 3, 3], -1, 1))]\n",
    "deco.call(inputs, [enco_states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_1f(tf.keras.Model):\n",
    "    def __init__(self, name='Encoder_Stack', cells=1, cell_input_shape=(1, 1, 64, 3, 3), lstm_layers=1, \n",
    "                 lstm_ksize_input=(3, 3), lstm_ksize_hidden=(5, 5),\n",
    "                 lstm_use_peepholes=True, lstm_cell_clip=None, \n",
    "                 lstm_bn_input_hidden=False, \n",
    "                 lstm_bn_hidden_hidden=False,\n",
    "                 lstm_bn_peepholes=False,):\n",
    "        \n",
    "        super(Encoder_1f, self).__init__(name=name)\n",
    "        self.cell_input_shape=cell_input_shape\n",
    "\n",
    "        # First Frame\n",
    "        self.encoder_cells = layers.ConvLSTM2D(input_shape = cell_input_shape,\n",
    "                                name=\"encoderConvLSTM{}\".format(1),\n",
    "                                filters = lstm_layers,\n",
    "                                kernel_size=lstm_ksize_input,\n",
    "                                padding='same',\n",
    "                                data_format='channels_first',\n",
    "                                return_sequences=True,\n",
    "                                return_state=True)\n",
    "        \n",
    "        \n",
    "\n",
    "        # input to call() will be a list of tensors of shape=(1, 1, 64, 3, 3)\n",
    "        # call() will take list of inputs and assign each to InputLayer\n",
    "        # call returns\n",
    "    def call(self, inputs_list):\n",
    "#             assert len(inputs_list) == len(self.input_layers), \"Input list length does not match # input layers in stack\"\n",
    "        assert len(inputs_list) == len(self.encoder_cells), \"Input list length does not match # encoder cells in stack\"\n",
    "\n",
    "        # connect each input to its corresponding InputLayer,\n",
    "        # and connect encoder hidden & cell states \n",
    "\n",
    "#             current_input = self.input_layers[0](inputs_list[0])\n",
    "        _, self.state_h, self.state_c = self.encoder_cells(inputs_list[0])\n",
    "        print(i, self.state_h.shape, self.state_c.shape)\n",
    "        self.encoder_states = [self.state_h, self.state_c]\n",
    "\n",
    "        return self.encoder_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "enco_1f = Encoder_1f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 64, 3, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enco_1f.cell_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'ResourceVariable' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-f6f830c740c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menco_1f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-f3b356acb8d3>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs_list)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#             assert len(inputs_list) == len(self.input_layers), \"Input list length does not match # input layers in stack\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_cells\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Input list length does not match # encoder cells in stack\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# connect each input to its corresponding InputLayer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'ResourceVariable' has no len()"
     ]
    }
   ],
   "source": [
    "enco_1f(tf.Variable(tf.random.uniform([1, 1, 64, 3, 3], -1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-26fa5c4c8de3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                   \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adadelta'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   metrics=['accuracy', 'mean_absolute_error'])\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0menco_1f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \"\"\"\n\u001b[1;32m   1345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   1347\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "\n",
    "enco_1f.compile(loss='mean_squared_error',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy', 'mean_absolute_error'])\n",
    "enco_1f.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
