{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLSTM functional encoder/decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.2.0-dlenv\n"
     ]
    }
   ],
   "source": [
    "print(\"tensorflow version:\",tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input dimension variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = 1\n",
    "channels = 1\n",
    "pixels_x = 21\n",
    "pixels_y = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Tensorflow and Keras don't have support for initial_state on ConvLSTM2D cells. \n",
    "Please follow the instructions here: https://stackoverflow.com/questions/50253138/convlstm2d-initial-state-assertion-error to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_convlstm_1f_1c_21x_21y\n"
     ]
    }
   ],
   "source": [
    "model_name = 'encoder_convlstm_'+str(frames)+'f_'+str(channels)+'c_'+str(pixels_x)+'x_'+str(pixels_y)+'y'\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input1 (InputLayer)     [(None, 1, 1, 21, 21 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder1 (ConvLSTM2D)           [(None, 1, 1, 21, 21 204         encoder_input1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input1 (InputLayer)     [(None, 1, 1, 21, 21 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder1 (ConvLSTM2D)           [(None, 1, 1, 21, 21 204         encoder_input1[0][0]             \n",
      "                                                                 encoder1[0][1]                   \n",
      "                                                                 encoder1[0][2]                   \n",
      "==================================================================================================\n",
      "Total params: 408\n",
      "Trainable params: 408\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##### ENCODER #####\n",
    "\n",
    "# first time-step\n",
    "i = 0\n",
    "input1 = layers.Input(name=\"encoder_input{}\".format(i+1),\n",
    "                      shape = (frames, channels, pixels_x, pixels_y))\n",
    "encoder_cell_1 = layers.ConvLSTM2D(name=\"encoder{}\".format(i+1),\n",
    "                                   filters = channels,\n",
    "                                   kernel_size=(5,5),\n",
    "                                   padding='same',\n",
    "                                   data_format='channels_first',\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "_, state_h, state_c = encoder_cell_1(input1)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "##### DECODER #####\n",
    "\n",
    "input2 = layers.Input(name=\"decoder_input{}\".format(i+1),\n",
    "                      shape = (frames, channels, pixels_x, pixels_y))\n",
    "decoder_cell_1 = layers.ConvLSTM2D(name=\"decoder{}\".format(i+1),\n",
    "                                   filters = channels,\n",
    "                                   kernel_size=(5,5),\n",
    "                                   padding='same',\n",
    "                                   data_format='channels_first',\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "decoder_output, _, _ = decoder_cell_1(input1, initial_state = encoder_states)\n",
    "\n",
    "##### COLLECT AND COMPILE #####\n",
    "encoder_stack = keras.Model(inputs = [input1, input2], \n",
    "                      outputs = decoder_output\n",
    "                     )\n",
    "\n",
    "encoder_stack.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['mean_absolute_error'])\n",
    "encoder_stack.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(\n",
    "    model = encoder_stack,\n",
    "    filepath = '../models/'+model_name+'.h5',\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format='tf',\n",
    "    signatures=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns train, inference_encoder and inference_decoder models\n",
    "def define_models(frames, channels, pixels_x, pixels_y):\n",
    "    n_output = channels * pixels_x * pixels_y\n",
    "    # define training encoder\n",
    "    encoder_inputs = layers.Input(name=\"encoder_input{}\".format(i+1),\n",
    "                      shape = (frames, channels, pixels_x, pixels_y))\n",
    "    encoder = layers.ConvLSTM2D(name=\"encoder{}\".format(i+1),\n",
    "                                   filters = channels,\n",
    "                                   kernel_size=(5,5),\n",
    "                                   padding='same',\n",
    "                                   strides=(1,1,1),\n",
    "                                   data_format='channels_first',\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    # define training decoder\n",
    "    decoder_inputs = layers.Input(name=\"decoder_input{}\".format(i+1),\n",
    "                      shape = (frames, channels, pixels_x, pixels_y))\n",
    "    decoder_lstm = layers.ConvLSTM2D(name=\"decoder{}\".format(i+1),\n",
    "                                   filters = channels,\n",
    "                                   kernel_size=(5,5),\n",
    "                                   padding='same',\n",
    "                                   strides=(1,1,1),\n",
    "                                   data_format='channels_first',\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    \n",
    "    decoder_dense = layers.Dense(n_output, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    # define inference encoder\n",
    "    encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = layers.Input(name=\"hidden_decoder_input{}\".format(i+1),\n",
    "                      shape = (frames, channels, pixels_x, pixels_y))\n",
    "    decoder_state_input_c = layers.Input(name=\"cell_decoder_input{}\".format(i+1),\n",
    "                      shape = (frames, channels, pixels_x, pixels_y))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = keras.Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    # return all models\n",
    "    return model, encoder_model, decoder_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `strides` argument must be a tuple of 2 integers. Received: (1, 1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-dd156537f03e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixels_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixels_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-802358c60f86>\u001b[0m in \u001b[0;36mdefine_models\u001b[0;34m(frames, channels, pixels_x, pixels_y)\u001b[0m\n\u001b[1;32m     12\u001b[0m                                    \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                    \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                                    return_state=True)\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mencoder_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional_recurrent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, return_sequences, go_backwards, stateful, dropout, recurrent_dropout, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                           \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                           \u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                           dtype=kwargs.get('dtype'))\n\u001b[0m\u001b[1;32m    864\u001b[0m     super(ConvLSTM2D, self).__init__(cell,\n\u001b[1;32m    865\u001b[0m                                      \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional_recurrent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kernel_size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'strides'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36mnormalize_tuple\u001b[0;34m(value, n, name)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m       raise ValueError('The `' + name + '` argument must be a tuple of ' +\n\u001b[0;32m---> 78\u001b[0;31m                        str(n) + ' integers. Received: ' + str(value))\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msingle_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue_tuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The `strides` argument must be a tuple of 2 integers. Received: (1, 1, 1)"
     ]
    }
   ],
   "source": [
    "model, encoder_model, decoder_model = define_models(frames, channels, pixels_x, pixels_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
