{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T01:27:39.627744Z",
     "start_time": "2020-06-12T01:27:17.659328Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'googleapiclient' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/distribute/cluster_resolver/tpu_cluster_resolver.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mcloud_tpu_client\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclient\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cloud_tpu_client'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9d84ac9c228f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# Ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandard_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# Namespaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/ops/standard_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloss_scaling_gradient_tape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/training/experimental/loss_scaling_gradient_tape.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/distribute/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcluster_resolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_device_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/distribute/cluster_resolver/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslurm_cluster_resolver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSlurmClusterResolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfconfig_cluster_resolver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTFConfigClusterResolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_cluster_resolver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/distribute/cluster_resolver/tpu_cluster_resolver.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0;34m'Falling back to TensorFlow client; we recommended you install the Cloud '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       'TPU client directly with pip install cloud-tpu-client.')\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_running_in_gce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/tensorflow/python/tpu/client/client.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0m_GOOGLE_API_CLIENT_INSTALLED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mapiclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdiscovery\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclient\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.7/site-packages/apiclient/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogleapiclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m _SUBMODULES = {\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'googleapiclient' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T01:27:39.856842Z",
     "start_time": "2020-06-12T01:27:24.634Z"
    }
   },
   "outputs": [],
   "source": [
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just make a model and experiment with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T00:04:54.559711Z",
     "start_time": "2020-06-12T00:04:54.555093Z"
    }
   },
   "outputs": [],
   "source": [
    "frames = 6\n",
    "channels = 1\n",
    "pixels_x = 21\n",
    "pixels_y = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture: encoder/decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Tensorflow and Keras don't have support for initial_state on ConvLSTM2D cells. \n",
    "Please follow the instructions here: https://stackoverflow.com/questions/50253138/convlstm2d-initial-state-assertion-error to fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoder model for fixed slice size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T00:49:20.490714Z",
     "start_time": "2020-06-12T00:49:19.149735Z"
    }
   },
   "outputs": [],
   "source": [
    "##### ENCODER #####\n",
    "\n",
    "# first time-step\n",
    "i = 0\n",
    "input1 = layers.Input(name=\"encoder_input{}\".format(i+1),\n",
    "                      shape = (1, channels, pixels_x, pixels_y))\n",
    "encoder_cell_1 = layers.ConvLSTM2D(name=\"encoder{}\".format(i+1),\n",
    "                            filters = 1, kernel_size=(5,5), padding='same',\n",
    "                            data_format='channels_first', return_sequences=True ,return_state=True)\n",
    "_, state_h, state_c = encoder_cell_1(input1)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "##### DECODER #####\n",
    "\n",
    "input2 = layers.Input(name=\"decoder_input{}\".format(i+1),\n",
    "                      shape = (1, channels, pixels_x, pixels_y))\n",
    "decoder_cell_1 = layers.ConvLSTM2D(name=\"decoder{}\".format(i+1),\n",
    "                            filters = 1, kernel_size=(5,5), padding='same',\n",
    "                            data_format='channels_first', return_sequences=True ,return_state=True)\n",
    "decoder_output, _, _ = decoder_cell_1(input1, initial_state = encoder_states)\n",
    "\n",
    "##### COLLECT AND COMPILE #####\n",
    "encoder_stack = Model(inputs = [input1, input2], \n",
    "                      outputs = decoder_output\n",
    "                     )\n",
    "\n",
    "encoder_stack.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['mean_absolute_error'])\n",
    "encoder_stack.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for loop to create for various slice sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T22:42:34.159602Z",
     "start_time": "2020-06-11T22:42:34.126531Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create generator to feed inputs to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T00:35:30.830630Z",
     "start_time": "2020-06-12T00:35:30.822148Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_array_slices_proc(array):\n",
    "    \"\"\"\n",
    "    Switch first and second dimensions of array and reshape to add empty dim in front. \n",
    "    Must know frames, channels, pixels_x, and pixels_y\n",
    "    \"\"\"\n",
    "    # switch first and second axes (in practice from (channels, frames, pixels_x, pixels_y) to (frames, channels, pixels_x, pixels_y) )\n",
    "    array = np.moveaxis(array, 0, 1)\n",
    "    # add empty dimension in front for ConvLSTMs\n",
    "    array.reshape(-1, 1, channels, pixels_x, pixels_y)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T00:49:55.221557Z",
     "start_time": "2020-06-12T00:49:55.189555Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import xarray as xr\n",
    "def generate_arrays(img_dir, slice_size=24, vars_=['t2m']):\n",
    "    \"\"\"\n",
    "    A generator that returns a list of slices (length = slice_size) as input, and another list of the subsequent 24-hour slice as output\n",
    "    \"\"\"\n",
    "    # get list of netcdf files in img_dir\n",
    "    netcdf_dirs = sorted(glob.glob(img_dir+\"/*.nc\"))\n",
    "    file_index = 0\n",
    "    # open first netcdf file\n",
    "    ds = xr.open_dataset(netcdf_dirs[file_index])\n",
    "    # select only some variables\n",
    "    ds = ds[vars_]\n",
    "    # counter is for hourly time slices. months with 31 days have 744 hours\n",
    "    counter = 0\n",
    "    while True: # generator needs to run infinitely\n",
    "        \n",
    "        # get input slice\n",
    "        input_images = []\n",
    "        output_images = []\n",
    "        for i in range(slice_size, 0, -1):\n",
    "            ds_slice = ds.isel(time=slice(counter+i, counter+i+1)).to_array().values\n",
    "            input_image_slice = get_array_slices_proc(ds_slice)\n",
    "            input_images.append(input_image_slice)\n",
    "        \n",
    "        # check if we're at the end of the month\n",
    "        if counter+2*slice_size > ds.sizes['time']:\n",
    "            # reset slice counter, increment to next netcdf file, open it, get output images\n",
    "            counter = 0\n",
    "            file_index += 1\n",
    "            if file_index == len(netcdf_dirs):\n",
    "                file_index=0\n",
    "                \n",
    "            ds = xr.open_dataset(netcdf_dirs[file_index])\n",
    "            # select only some variables\n",
    "            ds = ds[vars_]\n",
    "            # take slice 0-24 as output-image\n",
    "            for i in range(slice_size, 0, -1):\n",
    "                ds_slice = ds.isel(time=slice(counter+i, counter+i+1)).to_array().values\n",
    "                output_image_slice = get_array_slices_proc(ds_slice)\n",
    "                output_images.append(input_image_slice)\n",
    "            # set counter to -slice_size to reset for input on next iteration\n",
    "            counter -= slice_size\n",
    "        # get output slice right after input slice\n",
    "        else:\n",
    "            for i in range(slice_size, 0, -1):\n",
    "                ds_slice = ds.isel(time=slice(counter+slice_size+i, counter+slice_size+i+1)).to_array().values\n",
    "                output_image_slice = get_array_slices_proc(ds_slice)\n",
    "                output_images.append(input_image_slice)\n",
    "        \n",
    "        yield (input_images, output_images)\n",
    "        counter += slice_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T00:49:56.220313Z",
     "start_time": "2020-06-12T00:49:56.212126Z"
    }
   },
   "outputs": [],
   "source": [
    "train_file_path = \"../data/train\"\n",
    "validate_file_path = \"../data/validate\"\n",
    "\n",
    "# 3 years of training data = \n",
    "train_steps = 3 * 365 * 24 / 6 - 1\n",
    "# 1 year of validation data = \n",
    "valid_steps = 1 * 365 * 24 / 6 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T00:49:56.988379Z",
     "start_time": "2020-06-12T00:49:56.976868Z"
    }
   },
   "outputs": [],
   "source": [
    "gen = generate_arrays(train_file_path, slice_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T00:35:49.357240Z",
     "start_time": "2020-06-12T00:35:49.291362Z"
    }
   },
   "outputs": [],
   "source": [
    "in_, out_ = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T00:35:56.492264Z",
     "start_time": "2020-06-12T00:35:56.483091Z"
    }
   },
   "outputs": [],
   "source": [
    "out_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T00:50:01.408436Z",
     "start_time": "2020-06-12T00:49:59.963618Z"
    }
   },
   "outputs": [],
   "source": [
    "history = encoder_stack.fit_generator(\n",
    "    generate_arrays(train_file_path, slice_size=1),\n",
    "    steps_per_epoch = train_steps,\n",
    "    epochs = 20,\n",
    "    verbose = 1,\n",
    "    shuffle = False,\n",
    "    initial_epoch = 0,\n",
    "    validation_steps = valid_steps,\n",
    "    validation_data = generate_arrays(validate_file_path, slice_size=1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T17:33:58.607418Z",
     "start_time": "2020-06-09T17:33:58.519275Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "current_datetime = datetime.datetime.now().strftime(\"%Y_%M_%d_%H%M\")\n",
    "pickle.dump( history, open( \"../models/\"+current_datetime+\"_convlstm.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T22:14:25.290068Z",
     "start_time": "2020-06-11T22:14:23.236865Z"
    }
   },
   "outputs": [],
   "source": [
    "#rewrite model in Functional style\n",
    "\n",
    "# main input\n",
    "frame_input = layers.Input(shape=(frames, channels, pixels_x, pixels_y), name='frame_input')\n",
    "\n",
    "\n",
    "# ConvLSTM block\n",
    "stack = layers.ConvLSTM2D(filters=20, kernel_size=(5,5), padding='same',\n",
    "                       data_format='channels_first',return_sequences=True, name='ConvLSTM_1')(frame_input)\n",
    "stack = layers.BatchNormalization(axis=1, name='batchnorm_1')(stack)\n",
    "stack = layers.ConvLSTM2D(filters=10, kernel_size=(5,5), padding='same', \n",
    "                       data_format='channels_first',return_sequences=True, name='ConvLSTM_2')(stack)\n",
    "stack = layers.BatchNormalization(axis=1, name='batchnorm_2')(stack)\n",
    "stack = layers.ConvLSTM2D(filters=10, kernel_size=(1,1), padding='same', return_state=True,\n",
    "                       data_format='channels_first',return_sequences=True, name='ConvLSTM_3')(stack)\n",
    "\n",
    "\n",
    "# auxiliary input\n",
    "# auxiliary_input = layers.Input(shape=(5,), name='aux_input')\n",
    "# dense_input = layers.concatenate([clstm_out, auxiliary_input], name='concatenate_layer')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs = [frame_input], outputs = [stack])\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['mean_absolute_error'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
